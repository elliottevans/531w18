---
title: "Midterm Project"
date: "2/27/2018"
output:
  html_document:
    toc: true
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Raising a question

+ Nasdaq composite is a stock market index of the common stocks and similar securities listed on the NASDAQ stock market. It is one of the three most-followed indices in US stock markets. The composition of the NASDAQ Composite is heavily weighted towards information technology companies.[_from wikipedia_ https://en.wikipedia.org/wiki/NASDAQ]
+ People who engaged in IT and related fields can get some important information from the change of Nasdaq index. Like an IT company can assess their value and position in the whole field according to the price change of Nasdaq index.
+ It reflects the trend of US economy in some degree.
+ According to the reasons above, I get interested in exploring the price changing of Nasdaq index, and we using time series model to predict this change of a short future.

# 2. Data analysis

## 2.1 Explore the data

+ We first read in the data downloaded from [Yahoo Finance](https://finance.yahoo.com/quote/NDAQ?p=NDAQ).

```{r readin}
dat <- read.csv(file="NDAQ.csv",header=TRUE)
head(dat)
date <- as.Date(dat$Date)
price <- as.numeric(dat$Adj.Close)
```

+ Summary our data with six stastics index:

```{r summary, echo=FALSE}
summary(price)
```

+ Seeing that the scale of price is quite large. And the median price and mean price are very close to each other. Now we plot the change of log-adjusted closing price with time, here we use log-price is because the difference of log-price is the log-return of Nasdaq, it has economical meaning. <span id = "jump again">

```{r data, echo=FALSE}
plot(date,log(price),type="l",ylab="log(Adjusted Price)",main = "Nasdaq index")
abline(h=mean(log(price)),col = "blue")
```

+ The blue line is the total mean of our data, and seeing that there is a very obvious trend that the adjusted closing price is increasing with time goes by. Maybe we can start by a random walk with drift and to see if the model fits well.

## 2.2 Fitting with random walk model

+ The **random walk with drift** model is given by the difference equation:
<br><br>
$Y_n = Y_{n-1} + \mu + \epsilon_n$
<br><br>
driven by a white noise process ${\epsilon_n}$. This has solution: 
$$Y_n = Y_0 + n\mu + \sum_{k=1}^n\epsilon_k$$
+ To train our intuition, we can compare the data with simulations from a fitted model. A simple starting point is a Gaussian random walk with drift, having parameters estimated by:

```{r randomwalk}
N <- nrow(dat)
mu = mean(diff(log(price)))
sigma = sd(diff(log(price)))
set.seed(20180301)
X1 <- log(price[1])+cumsum(c(0,rnorm(N-1,mean=mu,sd=sigma)))
set.seed(03012018)
X2 <- log(price[1])+cumsum(c(0,rnorm(N-1,mean=mu,sd=sigma)))
par(mfrow=c(1,2))
plot(X1,type="l")
plot(X2,type="l")
```

+ It seems like that the left one is very similar to our data plot but the right one is far more different.
+ Let $y^*_{1:N}$ be the time series of Nasdaq daily closing values downloaded from yahoo.com. Let $z^*_n= \Delta \log y^*_n = \log y^*_{n}-\log y^*_{n-1}$.
+ Let's plot the sample autocorrelation function of the time series of Nasdaq log-returns, $z^*_{2:N}$.

```{r ACF}
z = diff(log(price))
acf(z)
acf(abs(z-mean(z)),lag.max=200)
```

+ For ACF of log-return it self, it looks pretty close to the ACF of white noise. There is some evidence for a small nonzero autocorrelation. However, as our data length is 756, the number of lags out of the dashed line is far more less than 5% of the whole data, which makes these nozero lags insignificant.
+ But seeing the ACF plot for absolute value, it's obvious that $z^*_{2:N}$ can't be a white noise process as there are many lags out of the dashed line and it must be larger than 5% of N, which means it's significant.
+ In conclusion, **random walk with drift** model fits not very well to our data.

## 2.3 Fitting with ARIMA model

+ We seperate data into training data and test data, choose last 10% as test data.

```{r}
dat_train = log(price[1:floor(0.9*length(price))])
dat_test = log(price[floor(0.9*length(price)):length(price)])
```

### 2.3.1 Choosing p, q and d

+ First we should decide the order of difference, i.e. value of d in ARIMA(p,d,q).
+ Usually people will pick d no more than 1, so let's start with d = 1.

```{r diff_order}
t = seq(from=1,length=floor(0.9*N)-1,by=1)
detrend_dat = diff(dat_train)
plot(t,detrend_dat,type="l",xlab="t",ylab="difference of log price",main = "Detrending Nasdaq index with d = 1")
abline(h=mean(detrend_dat),col = "blue")
```

+ It seems like there is no trend for one order of difference (mean stationary). We can fit our model under the null hyphosis with d = 1 firstly and then we can make some test to check this.
+ We seek to fit a stationary Gaussian ARIMA(p,1,q) model with parameter vector $\theta = (\phi_{1:p},\psi_{1:q},\mu,\sigma^2)$ given by:
$$\phi(B)((1-B)Y_n-\mu) = \psi(B)\varepsilon_n$$
where ${\epsilon_n}$ is a white noise process (i.e. $\sim iid N(0,\sigma^2)$);$\mu = E(X_n)$ is the trend; $\phi(x) = 1-\sum_{i=1}^p \phi_i x^i$ and $\psi(x) = 1+\sum_{i=1}^q \psi_i x^i$ are the ARMA polynomials; B is lag operator; $Y_n$ is the estimator of **log(Nasdaq adjusted closing price)**.
+ Next step is to choose appropriate p and q. Using Akaike¡¯s information criterion (AIC), which is computed as follows:
$$AIC = -2 \times l(\theta^*) + 2D$$
where $l(\theta^*)$ is the log-likelihood function deciding by parameter vector $\theta^*$ and $D$ is the number of parameters. The model with the lowest AIC score implies the least prediction error.
+ Let's make a table for choosing different p and q and there AIC score:

```{r AIC, echo=FALSE, message = FALSE, warning = FALSE}
aic_table <- function(data,P,Q){
  table <- matrix(NA,(P+1),(Q+1))
  for(p in 0:P) {
    for(q in 0:Q) {
      table[p+1,q+1] <- arima(data,order=c(p,1,q))$aic
    }
  }
  dimnames(table) <- list(paste("<b> AR",0:P, "</b>", sep=""),paste("MA",0:Q,sep=""))
  table
}
price_aic_table <- aic_table(dat_train,4,4)
require(knitr)
kable(price_aic_table,digits=2)
```

+ From the table above, it's easily to find that the two lowest AIC score appears at ARIMA(1,1,2) and ARIMA(2,1,1).
+ The models on their right and below them have both larger AIC scores and more complex models (i.e. larger p and q, which can causing invertibility and stability problems). That's not what we want, so we can exclude them.
+ The models on their left and upper have larger AIC scores with apparently differences. Thus, we can also exclude thinking about these models.

### 2.3.2 Regression on ARIMA models

+ We fit and diagnose two models simultaneously.

```{r regression}
price_arma12 = arima(dat_train,order=c(1,1,2)); price_arma12
price_arma21 = arima(dat_train,order=c(2,1,1)); price_arma21
```

+ We can get our two models from above:
<br><br>
For ARIMA(1,1,2):
$$(1+0.9068B)(1-B)Y_n = (1+0.8424B-0.1131B^2)\varepsilon_n$$
For ARIMA(2,1,1):
$$(1+1.0163B+0.1019B^2)(1-B)Y_n = (1+0.9587B)\varepsilon_n$$
+ From the results above, we can see that from Fisher information, the confidence interval (i.e. standard error) for all the coefficients are quite small so that zero is not covered in it. In a word, they are all significant under Fisher information. Also we can see that both of them don't have intercept terms, this indicates that the differences between adjacent log prices have a mean close to zero.
$$E(Y_n-Y_{n-1}) \approx 0$$
where $Y_n = log(price\ at\ time\ n)$

### 2.3.3 Test our models

+ Let's look at the roots for our models to check the casuality and invertibility

```{r}
# AR root for ARIMA(1,1,2) is outside of unit circle
MA_roots <- polyroot(c(1, coef(price_arma12)[c("ma1", "ma2")]))
MA_roots # MA root for ARIMA(1,1,2)
# MA root for ARIMA(2,1,1) is outside of unit circle
AR_roots <- polyroot(c(1, -coef(price_arma21)[c("ar1", "ar2")]))
AR_roots # AR root for ARIMA(2,1,1)
```

+ Seeing that all of the roots are just outside the unit circle, we can conclude that both two models can fit our data very well without stability problems.

## 2.4 Diagnostics

### 2.4.1 Seasonality

+ Although we didn't see any evidence of seasonality, people may suspect that the change of Nasdaq index may be affected by some seasonal influence and thus have seasonality effect. We check this under frequency domain.

```{r}
spectrum_price <-ts(dat_train,frequency=250)
spectrum(spectrum_price,spans=c(3,5,3))
```

+ Seeing that there aren't any significant peaks in periodogram above, this implies that there is no seasonality effect for fitting our data.

### 2.4.2 Normality of residuals

+ First let's plot the residuals and ACF plots of two models.

```{r}
par(mfrow = c(1,2))
plot(price_arma12$resid,ylab = "residuals",main = "Residuals for ARIMA(1,1,2) Model")
acf(price_arma12$resid,main = "ACF of residuals for ARIMA(1,1,2)")
par(mfrow = c(1,2))
plot(price_arma21$resid,ylab = "residuals",main = "Residuals for ARIMA(2,1,1) Model")
acf(price_arma21$resid,main = "ACF of residuals for ARIMA(2,1,1)")
```

+ For the first sight, there seems no big problem for residuals, the mean is stationary and around zero, ACF plots show that more than 95% lags are in the dashed line.
+ Using QQ-plot to check normality of residuals: <span id="jump">

```{r}
par(mfrow = c(1,2))
qqnorm(price_arma12$resid)
qqline(price_arma12$resid,probs = c(0.25,0.75))
qqnorm(price_arma21$resid)
qqline(price_arma21$resid,probs = c(0.25,0.75))
```

+ Both of the residuals have heavier tails than normal distribution, refusing normality assumption.

```{r}
library(forecast)
pred = predict(price_arma12, n.ahead = (N-floor(0.9*N)+1))$pred
forecast1 = forecast(price_arma12, h = 25)
plot(forecast1)
x = c((N-floor(0.1*N)-1):N)
lines(x, dat_test, type="l", col="red")
```

+ Using ARIMA(1,1,2) for example, the prediction of our test data is as above. We can see that the true data can only be covered by the border of 95% confidence interval. We need do some other method to improve our model.[_learn the code from_ http://blog.fens.me/r-ar/]

### 2.4.3 Modify our model

+ It seems like that Nasdaq index is also affected by some other factors.
+ Let's take volume as one of the considering factors in our model. We know that volume can affect the price apparently.

```{r}
volume = log(as.numeric(dat$Volume))
vol_train = log(volume[1:floor(0.9*length(price))])
vol_test = log(volume[floor(0.9*length(price)):length(price)])
```

+ repeat the steps in 2.3 and see how result change:

```{r AIC2, echo=FALSE, message = FALSE, warning = FALSE}
aic_table <- function(data,data2,P,Q){
  table <- matrix(NA,(P+1),(Q+1))
  for(p in 0:P) {
    for(q in 0:Q) {
      table[p+1,q+1] <- arima(data,order=c(p,1,q),xreg=data2)$aic
    }
  }
  dimnames(table) <- list(paste("<b> AR",0:P, "</b>", sep=""),paste("MA",0:Q,sep=""))
  table
}
price_aic_table2 <- aic_table(dat_train,vol_train,4,4)
require(knitr)
kable(price_aic_table2,digits=2)
```

+ Different from the result before, ARIMA(1,1,2) has the significant lowest score than other models. Thus, we choose ARIMA(1,1,2) as our model.

```{r}
arima112 <- arima(dat_train,order = c(1,1,2),xreg = vol_train)
arima112
```

+ Representing our model in math way:
$$\phi(B)((1-B)Y_n-\mu-\beta v_n) = \psi(B)\varepsilon_n$$
where the other notation is the same as before, and $v_n$ represents the value of volume at time n.
+ From the result above, our new model is:
$$(1+0.9620B)(1-B)(Y_n+0.0535) = (1+0.8911B-0.1028B^2)\varepsilon_n$$
+ Check the root:

```{r}
# AR root is outside the unit circle
MA_roots <- polyroot(c(1,coef(arima112)[c("ma1","ma2")]))
MA_roots # MA roots are outside the unit circle
```
+ Again, all the roots are just outside the unit circle.
+ Look at residuals:

```{r}
plot(arima112$resid,ylab = "residuals",main = "Residuals for ARIMA(1,1,2) Model with volume parameter")
acf(arima112$resid,main = "ACF of residuals with volume parameter")
```

+ Similar to previous result, the residuals seem to be a Gaussian process.
+ Check normality:

```{r}
qqnorm(arima112$resid)
qqline(arima112$resid,probs = c(0.25,0.75))
```

+ Although there is still havier tails than normal distribution, we can see that the tails are lighter than our original models in [2.3](#jump).
+ It implies that we can explore more other factors affecting Nasdaq index.
+ What's more, if we want to make a prediction with this model, we need make more efforts on predicting the change of volume also.

# 3. Conclusion

+ First we fit with a random walk model and we found significant evidence that the residuals can't be normal.
+ Then we fit our model with ARIMA(1,1,2) and ARIMA(2,1,1) models, finding that these two models have the same abilities on predicting the price. Both of them are very simple models.
+ When we diagnose our models, we check that there is no evidence for seasonality. Also we found evidence for non-normal residuals.Then we make a prediction with our model£¬finding that our models can't predict the furture prices very well.
+ The guess for fail on prediction is that in ARIMA model, we assume the trend is a constant, but the truth is not. We can see evidence from the orignal [data plot](#jump again). It shows that at the second half year of 2015, there is a very fast increase than other time.
+ We try to add other factors into our model. We assume that the trend has some relation to Volume, and it concludes that the model gets better than before. Also we drop one of the previous models. Only ARIMA(1,1,2) left.
+ The modification causes another problem, which is to predict the change of volume.
+ It's reasonal to guess that there are still some other factors influcing the change of Nasdaq prices. More complex model is needed. ARIMA is only a simple model to catch basic characteristics of the change of price.

## 3.1 Advantages

+ Make reasonal guesses on the model and check every assumption comprehensivly.
+ Find the potential problems and make modification.

## 3.2 Disadvantage

+ It will be more careful if we check taking one order difference (i.e. d=1) is enough.
+ Although the result shows that the roots for our model are outside the unit circle, some of them are very close to the boundary. We can go further on this problem.

# 4 Reference

+ Thanks for professor's lecture notes and previous midterm projects.[https://ionides.github.io/531w18/#midterm-project]
+ Other references has been noted above the report.